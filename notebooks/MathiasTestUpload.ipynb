{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amakarewicz/2022-DTU-Deep-Learning-Speech-Synthesis/blob/Mathias/notebooks/MathiasTestUpload.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aUfnHvacK5m"
      },
      "source": [
        "DiffWave implementation from LMNT - stealing by Mathias Vendt\n",
        "----\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.23.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.2.1 -> 22.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.13.0)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.4.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.2.1 -> 22.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchaudio in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.13.0)\n",
            "Requirement already satisfied: torch==1.13.0 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchaudio) (1.13.0)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==1.13.0->torchaudio) (4.4.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.2.1 -> 22.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.13.0)\n",
            "Requirement already satisfied: torchvision in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.14.0)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (9.3.0)\n",
            "Requirement already satisfied: requests in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (2.28.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (1.23.4)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (2022.9.24)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (1.26.12)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.2.1 -> 22.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboard in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.10.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (1.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (0.38.2)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (3.19.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (1.50.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (3.4.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (1.23.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (2.28.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (63.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (2.2.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (2.14.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.2.0)\n",
            "Requirement already satisfied: six>=1.9.0 in c:\\users\\mathias vendt\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2022.9.24)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.12)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\mathias vendt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.2.1 -> 22.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tqdm\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "     ---------------------------------------- 78.5/78.5 kB 4.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: colorama in c:\\users\\mathias vendt\\appdata\\roaming\\python\\python310\\site-packages (from tqdm) (0.4.6)\n",
            "Installing collected packages: tqdm\n",
            "Successfully installed tqdm-4.64.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.2.1 -> 22.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# requirements\n",
        "!Pip install numpy\n",
        "!Pip install torch \n",
        "!Pip install torchaudio\n",
        "!Pip install torch torchvision\n",
        "!Pip install tensorboard \n",
        "!Pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--max_steps MAX_STEPS] [--fp16]\n",
            "                             model_dir data_dirs [data_dirs ...]\n",
            "ipykernel_launcher.py: error: argument --fp16: ignored explicit argument '\"c:\\\\Users\\\\Mathias Vendt\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v2-15020ZcR9dmRO6PE5.json\"'\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\Mathias Vendt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\argparse.py:1859\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1858\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1859\u001b[0m     namespace, args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_known_args(args, namespace)\n\u001b[0;32m   1860\u001b[0m \u001b[39mexcept\u001b[39;00m ArgumentError:\n",
            "File \u001b[1;32mc:\\Users\\Mathias Vendt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\argparse.py:2068\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args\u001b[1;34m(self, arg_strings, namespace)\u001b[0m\n\u001b[0;32m   2067\u001b[0m     \u001b[39m# consume the next optional and any arguments for it\u001b[39;00m\n\u001b[1;32m-> 2068\u001b[0m     start_index \u001b[39m=\u001b[39m consume_optional(start_index)\n\u001b[0;32m   2070\u001b[0m \u001b[39m# consume any positionals following the last Optional\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Mathias Vendt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\argparse.py:1990\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args.<locals>.consume_optional\u001b[1;34m(start_index)\u001b[0m\n\u001b[0;32m   1989\u001b[0m         msg \u001b[39m=\u001b[39m _(\u001b[39m'\u001b[39m\u001b[39mignored explicit argument \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1990\u001b[0m         \u001b[39mraise\u001b[39;00m ArgumentError(action, msg \u001b[39m%\u001b[39m explicit_arg)\n\u001b[0;32m   1992\u001b[0m \u001b[39m# if there is no explicit argument, try to match the\u001b[39;00m\n\u001b[0;32m   1993\u001b[0m \u001b[39m# optional's string arguments with the following strings\u001b[39;00m\n\u001b[0;32m   1994\u001b[0m \u001b[39m# if successful, exit the loop\u001b[39;00m\n\u001b[0;32m   1995\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "\u001b[1;31mArgumentError\u001b[0m: argument --fp16: ignored explicit argument '\"c:\\\\Users\\\\Mathias Vendt\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v2-15020ZcR9dmRO6PE5.json\"'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "Cell \u001b[1;32mIn [50], line 53\u001b[0m\n\u001b[0;32m     51\u001b[0m parser\u001b[39m.\u001b[39madd_argument(\u001b[39m'\u001b[39m\u001b[39m--fp16\u001b[39m\u001b[39m'\u001b[39m, action\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstore_true\u001b[39m\u001b[39m'\u001b[39m, default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     52\u001b[0m     help\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39muse 16-bit floating point operations for training\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m main(parser\u001b[39m.\u001b[39;49mparse_args())\n",
            "File \u001b[1;32mc:\\Users\\Mathias Vendt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\argparse.py:1826\u001b[0m, in \u001b[0;36mArgumentParser.parse_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1825\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_args\u001b[39m(\u001b[39mself\u001b[39m, args\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, namespace\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 1826\u001b[0m     args, argv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse_known_args(args, namespace)\n\u001b[0;32m   1827\u001b[0m     \u001b[39mif\u001b[39;00m argv:\n",
            "File \u001b[1;32mc:\\Users\\Mathias Vendt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\argparse.py:1862\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1861\u001b[0m         err \u001b[39m=\u001b[39m _sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m1\u001b[39m]\n\u001b[1;32m-> 1862\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror(\u001b[39mstr\u001b[39;49m(err))\n\u001b[0;32m   1863\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\Mathias Vendt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\argparse.py:2583\u001b[0m, in \u001b[0;36mArgumentParser.error\u001b[1;34m(self, message)\u001b[0m\n\u001b[0;32m   2582\u001b[0m args \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mprog\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprog, \u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m: message}\n\u001b[1;32m-> 2583\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexit(\u001b[39m2\u001b[39;49m, _(\u001b[39m'\u001b[39;49m\u001b[39m%(prog)s\u001b[39;49;00m\u001b[39m: error: \u001b[39;49m\u001b[39m%(message)s\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m) \u001b[39m%\u001b[39;49m args)\n",
            "File \u001b[1;32mc:\\Users\\Mathias Vendt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\argparse.py:2570\u001b[0m, in \u001b[0;36mArgumentParser.exit\u001b[1;34m(self, status, message)\u001b[0m\n\u001b[0;32m   2569\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_print_message(message, _sys\u001b[39m.\u001b[39mstderr)\n\u001b[1;32m-> 2570\u001b[0m _sys\u001b[39m.\u001b[39;49mexit(status)\n",
            "\u001b[1;31mSystemExit\u001b[0m: 2",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py:2042\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2039\u001b[0m \u001b[39mif\u001b[39;00m exception_only:\n\u001b[0;32m   2040\u001b[0m     stb \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mAn exception has occurred, use \u001b[39m\u001b[39m%\u001b[39m\u001b[39mtb to see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   2041\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mthe full traceback.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m]\n\u001b[1;32m-> 2042\u001b[0m     stb\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mInteractiveTB\u001b[39m.\u001b[39;49mget_exception_only(etype,\n\u001b[0;32m   2043\u001b[0m                                                      value))\n\u001b[0;32m   2044\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2045\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   2046\u001b[0m         \u001b[39m# Exception classes can customise their traceback - we\u001b[39;00m\n\u001b[0;32m   2047\u001b[0m         \u001b[39m# use this in IPython.parallel for exceptions occurring\u001b[39;00m\n\u001b[0;32m   2048\u001b[0m         \u001b[39m# in the engines. This should return a list of strings.\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py:579\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_exception_only\u001b[39m(\u001b[39mself\u001b[39m, etype, value):\n\u001b[0;32m    572\u001b[0m     \u001b[39m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \n\u001b[0;32m    574\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[39m    value : exception value\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 579\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39;49mstructured_traceback(\u001b[39mself\u001b[39;49m, etype, value)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py:446\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    443\u001b[0m     chained_exc_ids\u001b[39m.\u001b[39madd(\u001b[39mid\u001b[39m(exception[\u001b[39m1\u001b[39m]))\n\u001b[0;32m    444\u001b[0m     chained_exceptions_tb_offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    445\u001b[0m     out_list \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 446\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m    447\u001b[0m             etype, evalue, (etb, chained_exc_ids),\n\u001b[0;32m    448\u001b[0m             chained_exceptions_tb_offset, context)\n\u001b[0;32m    449\u001b[0m         \u001b[39m+\u001b[39m chained_exception_message\n\u001b[0;32m    450\u001b[0m         \u001b[39m+\u001b[39m out_list)\n\u001b[0;32m    452\u001b[0m \u001b[39mreturn\u001b[39;00m out_list\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py:1112\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1110\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1111\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtb \u001b[39m=\u001b[39m tb\n\u001b[1;32m-> 1112\u001b[0m \u001b[39mreturn\u001b[39;00m FormattedTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m   1113\u001b[0m     \u001b[39mself\u001b[39;49m, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py:1006\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1003\u001b[0m mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\n\u001b[0;32m   1004\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose_modes:\n\u001b[0;32m   1005\u001b[0m     \u001b[39m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[1;32m-> 1006\u001b[0m     \u001b[39mreturn\u001b[39;00m VerboseTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m   1007\u001b[0m         \u001b[39mself\u001b[39;49m, etype, value, tb, tb_offset, number_of_lines_of_context\n\u001b[0;32m   1008\u001b[0m     )\n\u001b[0;32m   1009\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMinimal\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m   1010\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39mget_exception_only(\u001b[39mself\u001b[39m, etype, value)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py:859\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m    850\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstructured_traceback\u001b[39m(\n\u001b[0;32m    851\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    852\u001b[0m     etype: \u001b[39mtype\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    856\u001b[0m     number_of_lines_of_context: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m,\n\u001b[0;32m    857\u001b[0m ):\n\u001b[0;32m    858\u001b[0m     \u001b[39m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m     formatted_exception \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m    860\u001b[0m                                                            tb_offset)\n\u001b[0;32m    862\u001b[0m     colors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mColors  \u001b[39m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[0;32m    863\u001b[0m     colorsnormal \u001b[39m=\u001b[39m colors\u001b[39m.\u001b[39mNormal  \u001b[39m# used a lot\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py:793\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(tb_offset, \u001b[39mint\u001b[39m)\n\u001b[0;32m    791\u001b[0m head \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_header(etype, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlong_header)\n\u001b[0;32m    792\u001b[0m records \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 793\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_records(etb, number_of_lines_of_context, tb_offset) \u001b[39mif\u001b[39;00m etb \u001b[39melse\u001b[39;00m []\n\u001b[0;32m    794\u001b[0m )\n\u001b[0;32m    796\u001b[0m frames \u001b[39m=\u001b[39m []\n\u001b[0;32m    797\u001b[0m skipped \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py:848\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m    842\u001b[0m     formatter \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    843\u001b[0m options \u001b[39m=\u001b[39m stack_data\u001b[39m.\u001b[39mOptions(\n\u001b[0;32m    844\u001b[0m     before\u001b[39m=\u001b[39mbefore,\n\u001b[0;32m    845\u001b[0m     after\u001b[39m=\u001b[39mafter,\n\u001b[0;32m    846\u001b[0m     pygments_formatter\u001b[39m=\u001b[39mformatter,\n\u001b[0;32m    847\u001b[0m )\n\u001b[1;32m--> 848\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(stack_data\u001b[39m.\u001b[39;49mFrameInfo\u001b[39m.\u001b[39;49mstack_data(etb, options\u001b[39m=\u001b[39;49moptions))[tb_offset:]\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\stack_data\\core.py:564\u001b[0m, in \u001b[0;36mFrameInfo.stack_data\u001b[1;34m(cls, frame_or_tb, options, collapse_repeated_frames)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    549\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstack_data\u001b[39m(\n\u001b[0;32m    550\u001b[0m         \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    554\u001b[0m         collapse_repeated_frames: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    555\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Union[\u001b[39m'\u001b[39m\u001b[39mFrameInfo\u001b[39m\u001b[39m'\u001b[39m, RepeatedFrames]]:\n\u001b[0;32m    556\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    557\u001b[0m \u001b[39m    An iterator of FrameInfo and RepeatedFrames objects representing\u001b[39;00m\n\u001b[0;32m    558\u001b[0m \u001b[39m    a full traceback or stack. Similar consecutive frames are collapsed into RepeatedFrames\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[39m    and optionally an Options object to configure.\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 564\u001b[0m     stack \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(iter_stack(frame_or_tb))\n\u001b[0;32m    566\u001b[0m     \u001b[39m# Reverse the stack from a frame so that it's in the same order\u001b[39;00m\n\u001b[0;32m    567\u001b[0m     \u001b[39m# as the order from a traceback, which is the order of a printed\u001b[39;00m\n\u001b[0;32m    568\u001b[0m     \u001b[39m# traceback when read top to bottom (most recent call last)\u001b[39;00m\n\u001b[0;32m    569\u001b[0m     \u001b[39mif\u001b[39;00m is_frame(frame_or_tb):\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\stack_data\\utils.py:97\u001b[0m, in \u001b[0;36miter_stack\u001b[1;34m(frame_or_tb)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39mwhile\u001b[39;00m frame_or_tb:\n\u001b[0;32m     96\u001b[0m     \u001b[39myield\u001b[39;00m frame_or_tb\n\u001b[1;32m---> 97\u001b[0m     \u001b[39mif\u001b[39;00m is_frame(frame_or_tb):\n\u001b[0;32m     98\u001b[0m         frame_or_tb \u001b[39m=\u001b[39m frame_or_tb\u001b[39m.\u001b[39mf_back\n\u001b[0;32m     99\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\stack_data\\utils.py:90\u001b[0m, in \u001b[0;36mis_frame\u001b[1;34m(frame_or_tb)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_frame\u001b[39m(frame_or_tb: Union[FrameType, TracebackType]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m---> 90\u001b[0m     assert_(\u001b[39misinstance\u001b[39;49m(frame_or_tb, (types\u001b[39m.\u001b[39;49mFrameType, types\u001b[39m.\u001b[39;49mTracebackType)))\n\u001b[0;32m     91\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39misinstance\u001b[39m(frame_or_tb, (types\u001b[39m.\u001b[39mFrameType,))\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\stack_data\\utils.py:171\u001b[0m, in \u001b[0;36massert_\u001b[1;34m(condition, error)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(error, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    170\u001b[0m     error \u001b[39m=\u001b[39m \u001b[39mAssertionError\u001b[39;00m(error)\n\u001b[1;32m--> 171\u001b[0m \u001b[39mraise\u001b[39;00m error\n",
            "\u001b[1;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# __main__.py\n",
        "# Copyright 2020 LMNT, Inc. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "from argparse import ArgumentParser\n",
        "from torch.cuda import device_count\n",
        "from torch.multiprocessing import spawn\n",
        "\n",
        "#from diffwave.learner import train, train_distributed\n",
        "#from diffwave.params import params\n",
        "\n",
        "\n",
        "def _get_free_port():\n",
        "  import socketserver\n",
        "  with socketserver.TCPServer(('localhost', 0), None) as s:\n",
        "    return s.server_address[1]\n",
        "\n",
        "\n",
        "def main(args):\n",
        "  replica_count = device_count()\n",
        "  if replica_count > 1:\n",
        "    if params.batch_size % replica_count != 0:\n",
        "      raise ValueError(f'Batch size {params.batch_size} is not evenly divisble by # GPUs {replica_count}.')\n",
        "    params.batch_size = params.batch_size // replica_count\n",
        "    port = _get_free_port()\n",
        "    spawn(train_distributed, args=(replica_count, port, args, params), nprocs=replica_count, join=True)\n",
        "  else:\n",
        "    train(args, params)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  parser = ArgumentParser(description='train (or resume training) a DiffWave model')\n",
        "  parser.add_argument('model_dir',\n",
        "      help='directory in which to store model checkpoints and training logs')\n",
        "  parser.add_argument('data_dirs', nargs='+',\n",
        "      help='space separated list of directories from which to read .wav files for training')\n",
        "  parser.add_argument('--max_steps', default=None, type=int,\n",
        "      help='maximum number of training steps')\n",
        "  parser.add_argument('--fp16', action='store_true', default=False,\n",
        "      help='use 16-bit floating point operations for training')\n",
        "  main(parser.parse_args())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dataset.py\n",
        "# Copyright 2020 LMNT, Inc. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "\n",
        "from glob import glob\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "\n",
        "\n",
        "class ConditionalDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, paths):\n",
        "    super().__init__()\n",
        "    self.filenames = []\n",
        "    for path in paths:\n",
        "      self.filenames += glob(f'{path}/**/*.wav', recursive=True)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.filenames)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    audio_filename = self.filenames[idx]\n",
        "    spec_filename = f'{audio_filename}.spec.npy'\n",
        "    signal, _ = torchaudio.load(audio_filename)\n",
        "    spectrogram = np.load(spec_filename)\n",
        "    return {\n",
        "        'audio': signal[0],\n",
        "        'spectrogram': spectrogram.T\n",
        "    }\n",
        "\n",
        "\n",
        "class UnconditionalDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, paths):\n",
        "    super().__init__()\n",
        "    self.filenames = []\n",
        "    for path in paths:\n",
        "      self.filenames += glob(f'{path}/**/*.wav', recursive=True)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.filenames)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    audio_filename = self.filenames[idx]\n",
        "    spec_filename = f'{audio_filename}.spec.npy'\n",
        "    signal, _ = torchaudio.load(audio_filename)\n",
        "    return {\n",
        "        'audio': signal[0],\n",
        "        'spectrogram': None\n",
        "    }\n",
        "\n",
        "\n",
        "class Collator:\n",
        "  def __init__(self, params):\n",
        "    self.params = params\n",
        "\n",
        "  def collate(self, minibatch):\n",
        "    samples_per_frame = self.params.hop_samples\n",
        "    for record in minibatch:\n",
        "      if self.params.unconditional:\n",
        "          # Filter out records that aren't long enough.\n",
        "          if len(record['audio']) < self.params.audio_len:\n",
        "            del record['spectrogram']\n",
        "            del record['audio']\n",
        "            continue\n",
        "\n",
        "          start = random.randint(0, record['audio'].shape[-1] - self.params.audio_len)\n",
        "          end = start + self.params.audio_len\n",
        "          record['audio'] = record['audio'][start:end]\n",
        "          record['audio'] = np.pad(record['audio'], (0, (end - start) - len(record['audio'])), mode='constant')\n",
        "      else:\n",
        "          # Filter out records that aren't long enough.\n",
        "          if len(record['spectrogram']) < self.params.crop_mel_frames:\n",
        "            del record['spectrogram']\n",
        "            del record['audio']\n",
        "            continue\n",
        "\n",
        "          start = random.randint(0, record['spectrogram'].shape[0] - self.params.crop_mel_frames)\n",
        "          end = start + self.params.crop_mel_frames\n",
        "          record['spectrogram'] = record['spectrogram'][start:end].T\n",
        "\n",
        "          start *= samples_per_frame\n",
        "          end *= samples_per_frame\n",
        "          record['audio'] = record['audio'][start:end]\n",
        "          record['audio'] = np.pad(record['audio'], (0, (end-start) - len(record['audio'])), mode='constant')\n",
        "\n",
        "    audio = np.stack([record['audio'] for record in minibatch if 'audio' in record])\n",
        "    if self.params.unconditional:\n",
        "        return {\n",
        "            'audio': torch.from_numpy(audio),\n",
        "            'spectrogram': None,\n",
        "        }\n",
        "    spectrogram = np.stack([record['spectrogram'] for record in minibatch if 'spectrogram' in record])\n",
        "    return {\n",
        "        'audio': torch.from_numpy(audio),\n",
        "        'spectrogram': torch.from_numpy(spectrogram),\n",
        "    }\n",
        "\n",
        "  # for gtzan\n",
        "  def collate_gtzan(self, minibatch):\n",
        "    ldata = []\n",
        "    mean_audio_len = self.params.audio_len # change to fit in gpu memory\n",
        "    # audio total generated time = audio_len * sample_rate\n",
        "    # GTZAN statistics\n",
        "    # max len audio 675808; min len audio sample 660000; mean len audio sample 662117\n",
        "    # max audio sample 1; min audio sample -1; mean audio sample -0.0010 (normalized)\n",
        "    # sample rate of all is 22050\n",
        "    for data in minibatch:\n",
        "      if data[0].shape[-1] < mean_audio_len:  # pad\n",
        "        data_audio = F.pad(data[0], (0, mean_audio_len - data[0].shape[-1]), mode='constant', value=0)\n",
        "      elif data[0].shape[-1] > mean_audio_len:  # crop\n",
        "        start = random.randint(0, data[0].shape[-1] - mean_audio_len)\n",
        "        end = start + mean_audio_len\n",
        "        data_audio = data[0][:, start:end]\n",
        "      else:\n",
        "        data_audio = data[0]\n",
        "      ldata.append(data_audio)\n",
        "    audio = torch.cat(ldata, dim=0)\n",
        "    return {\n",
        "          'audio': audio,\n",
        "          'spectrogram': None,\n",
        "    }\n",
        "\n",
        "\n",
        "def from_path(data_dirs, params, is_distributed=False):\n",
        "  if params.unconditional:\n",
        "    dataset = UnconditionalDataset(data_dirs)\n",
        "  else:#with condition\n",
        "    dataset = ConditionalDataset(data_dirs)\n",
        "  return torch.utils.data.DataLoader(\n",
        "      dataset,\n",
        "      batch_size=params.batch_size,\n",
        "      collate_fn=Collator(params).collate,\n",
        "      shuffle=not is_distributed,\n",
        "      num_workers=os.cpu_count(),\n",
        "      sampler=DistributedSampler(dataset) if is_distributed else None,\n",
        "      pin_memory=True,\n",
        "      drop_last=True)\n",
        "\n",
        "\n",
        "def from_gtzan(params, is_distributed=False):\n",
        "  dataset = torchaudio.datasets.GTZAN('./data', download=True)\n",
        "  return torch.utils.data.DataLoader(\n",
        "      dataset,\n",
        "      batch_size=params.batch_size,\n",
        "      collate_fn=Collator(params).collate_gtzan,\n",
        "      shuffle=not is_distributed,\n",
        "      num_workers=os.cpu_count(),\n",
        "      sampler=DistributedSampler(dataset) if is_distributed else None,\n",
        "      pin_memory=True,\n",
        "      drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--spectrogram_path SPECTROGRAM_PATH]\n",
            "                             [--output OUTPUT] [--fast]\n",
            "                             model_dir\n",
            "ipykernel_launcher.py: error: argument --fast/-f: ignored explicit argument '\"c:\\\\Users\\\\Mathias Vendt\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v2-15020ZcR9dmRO6PE5.json\"'\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\Mathias Vendt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\argparse.py:1859\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1858\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1859\u001b[0m     namespace, args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_known_args(args, namespace)\n\u001b[0;32m   1860\u001b[0m \u001b[39mexcept\u001b[39;00m ArgumentError:\n",
            "File \u001b[1;32mc:\\Users\\Mathias Vendt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\argparse.py:2068\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args\u001b[1;34m(self, arg_strings, namespace)\u001b[0m\n\u001b[0;32m   2067\u001b[0m     \u001b[39m# consume the next optional and any arguments for it\u001b[39;00m\n\u001b[1;32m-> 2068\u001b[0m     start_index \u001b[39m=\u001b[39m consume_optional(start_index)\n\u001b[0;32m   2070\u001b[0m \u001b[39m# consume any positionals following the last Optional\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Mathias Vendt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\argparse.py:1990\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args.<locals>.consume_optional\u001b[1;34m(start_index)\u001b[0m\n\u001b[0;32m   1989\u001b[0m         msg \u001b[39m=\u001b[39m _(\u001b[39m'\u001b[39m\u001b[39mignored explicit argument \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1990\u001b[0m         \u001b[39mraise\u001b[39;00m ArgumentError(action, msg \u001b[39m%\u001b[39m explicit_arg)\n\u001b[0;32m   1992\u001b[0m \u001b[39m# if there is no explicit argument, try to match the\u001b[39;00m\n\u001b[0;32m   1993\u001b[0m \u001b[39m# optional's string arguments with the following strings\u001b[39;00m\n\u001b[0;32m   1994\u001b[0m \u001b[39m# if successful, exit the loop\u001b[39;00m\n\u001b[0;32m   1995\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "\u001b[1;31mArgumentError\u001b[0m: argument --fast/-f: ignored explicit argument '\"c:\\\\Users\\\\Mathias Vendt\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v2-15020ZcR9dmRO6PE5.json\"'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "Cell \u001b[1;32mIn [47], line 112\u001b[0m\n\u001b[0;32m    110\u001b[0m parser\u001b[39m.\u001b[39madd_argument(\u001b[39m'\u001b[39m\u001b[39m--fast\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m-f\u001b[39m\u001b[39m'\u001b[39m, action\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstore_true\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    111\u001b[0m     help\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfast sampling procedure\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 112\u001b[0m main(parser\u001b[39m.\u001b[39;49mparse_args())\n",
            "File \u001b[1;32mc:\\Users\\Mathias Vendt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\argparse.py:1826\u001b[0m, in \u001b[0;36mArgumentParser.parse_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1825\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_args\u001b[39m(\u001b[39mself\u001b[39m, args\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, namespace\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 1826\u001b[0m     args, argv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse_known_args(args, namespace)\n\u001b[0;32m   1827\u001b[0m     \u001b[39mif\u001b[39;00m argv:\n",
            "File \u001b[1;32mc:\\Users\\Mathias Vendt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\argparse.py:1862\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1861\u001b[0m         err \u001b[39m=\u001b[39m _sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m1\u001b[39m]\n\u001b[1;32m-> 1862\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror(\u001b[39mstr\u001b[39;49m(err))\n\u001b[0;32m   1863\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\Mathias Vendt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\argparse.py:2583\u001b[0m, in \u001b[0;36mArgumentParser.error\u001b[1;34m(self, message)\u001b[0m\n\u001b[0;32m   2582\u001b[0m args \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mprog\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprog, \u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m: message}\n\u001b[1;32m-> 2583\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexit(\u001b[39m2\u001b[39;49m, _(\u001b[39m'\u001b[39;49m\u001b[39m%(prog)s\u001b[39;49;00m\u001b[39m: error: \u001b[39;49m\u001b[39m%(message)s\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m) \u001b[39m%\u001b[39;49m args)\n",
            "File \u001b[1;32mc:\\Users\\Mathias Vendt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\argparse.py:2570\u001b[0m, in \u001b[0;36mArgumentParser.exit\u001b[1;34m(self, status, message)\u001b[0m\n\u001b[0;32m   2569\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_print_message(message, _sys\u001b[39m.\u001b[39mstderr)\n\u001b[1;32m-> 2570\u001b[0m _sys\u001b[39m.\u001b[39;49mexit(status)\n",
            "\u001b[1;31mSystemExit\u001b[0m: 2",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py:2042\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2039\u001b[0m \u001b[39mif\u001b[39;00m exception_only:\n\u001b[0;32m   2040\u001b[0m     stb \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mAn exception has occurred, use \u001b[39m\u001b[39m%\u001b[39m\u001b[39mtb to see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   2041\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mthe full traceback.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m]\n\u001b[1;32m-> 2042\u001b[0m     stb\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mInteractiveTB\u001b[39m.\u001b[39;49mget_exception_only(etype,\n\u001b[0;32m   2043\u001b[0m                                                      value))\n\u001b[0;32m   2044\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2045\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   2046\u001b[0m         \u001b[39m# Exception classes can customise their traceback - we\u001b[39;00m\n\u001b[0;32m   2047\u001b[0m         \u001b[39m# use this in IPython.parallel for exceptions occurring\u001b[39;00m\n\u001b[0;32m   2048\u001b[0m         \u001b[39m# in the engines. This should return a list of strings.\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py:579\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_exception_only\u001b[39m(\u001b[39mself\u001b[39m, etype, value):\n\u001b[0;32m    572\u001b[0m     \u001b[39m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \n\u001b[0;32m    574\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[39m    value : exception value\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 579\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39;49mstructured_traceback(\u001b[39mself\u001b[39;49m, etype, value)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py:446\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    443\u001b[0m     chained_exc_ids\u001b[39m.\u001b[39madd(\u001b[39mid\u001b[39m(exception[\u001b[39m1\u001b[39m]))\n\u001b[0;32m    444\u001b[0m     chained_exceptions_tb_offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    445\u001b[0m     out_list \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 446\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m    447\u001b[0m             etype, evalue, (etb, chained_exc_ids),\n\u001b[0;32m    448\u001b[0m             chained_exceptions_tb_offset, context)\n\u001b[0;32m    449\u001b[0m         \u001b[39m+\u001b[39m chained_exception_message\n\u001b[0;32m    450\u001b[0m         \u001b[39m+\u001b[39m out_list)\n\u001b[0;32m    452\u001b[0m \u001b[39mreturn\u001b[39;00m out_list\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py:1112\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1110\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1111\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtb \u001b[39m=\u001b[39m tb\n\u001b[1;32m-> 1112\u001b[0m \u001b[39mreturn\u001b[39;00m FormattedTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m   1113\u001b[0m     \u001b[39mself\u001b[39;49m, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py:1006\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1003\u001b[0m mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\n\u001b[0;32m   1004\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose_modes:\n\u001b[0;32m   1005\u001b[0m     \u001b[39m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[1;32m-> 1006\u001b[0m     \u001b[39mreturn\u001b[39;00m VerboseTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m   1007\u001b[0m         \u001b[39mself\u001b[39;49m, etype, value, tb, tb_offset, number_of_lines_of_context\n\u001b[0;32m   1008\u001b[0m     )\n\u001b[0;32m   1009\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMinimal\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m   1010\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39mget_exception_only(\u001b[39mself\u001b[39m, etype, value)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py:859\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m    850\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstructured_traceback\u001b[39m(\n\u001b[0;32m    851\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    852\u001b[0m     etype: \u001b[39mtype\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    856\u001b[0m     number_of_lines_of_context: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m,\n\u001b[0;32m    857\u001b[0m ):\n\u001b[0;32m    858\u001b[0m     \u001b[39m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m     formatted_exception \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m    860\u001b[0m                                                            tb_offset)\n\u001b[0;32m    862\u001b[0m     colors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mColors  \u001b[39m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[0;32m    863\u001b[0m     colorsnormal \u001b[39m=\u001b[39m colors\u001b[39m.\u001b[39mNormal  \u001b[39m# used a lot\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py:793\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(tb_offset, \u001b[39mint\u001b[39m)\n\u001b[0;32m    791\u001b[0m head \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_header(etype, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlong_header)\n\u001b[0;32m    792\u001b[0m records \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 793\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_records(etb, number_of_lines_of_context, tb_offset) \u001b[39mif\u001b[39;00m etb \u001b[39melse\u001b[39;00m []\n\u001b[0;32m    794\u001b[0m )\n\u001b[0;32m    796\u001b[0m frames \u001b[39m=\u001b[39m []\n\u001b[0;32m    797\u001b[0m skipped \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py:848\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m    842\u001b[0m     formatter \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    843\u001b[0m options \u001b[39m=\u001b[39m stack_data\u001b[39m.\u001b[39mOptions(\n\u001b[0;32m    844\u001b[0m     before\u001b[39m=\u001b[39mbefore,\n\u001b[0;32m    845\u001b[0m     after\u001b[39m=\u001b[39mafter,\n\u001b[0;32m    846\u001b[0m     pygments_formatter\u001b[39m=\u001b[39mformatter,\n\u001b[0;32m    847\u001b[0m )\n\u001b[1;32m--> 848\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(stack_data\u001b[39m.\u001b[39;49mFrameInfo\u001b[39m.\u001b[39;49mstack_data(etb, options\u001b[39m=\u001b[39;49moptions))[tb_offset:]\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\stack_data\\core.py:564\u001b[0m, in \u001b[0;36mFrameInfo.stack_data\u001b[1;34m(cls, frame_or_tb, options, collapse_repeated_frames)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    549\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstack_data\u001b[39m(\n\u001b[0;32m    550\u001b[0m         \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    554\u001b[0m         collapse_repeated_frames: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    555\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Union[\u001b[39m'\u001b[39m\u001b[39mFrameInfo\u001b[39m\u001b[39m'\u001b[39m, RepeatedFrames]]:\n\u001b[0;32m    556\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    557\u001b[0m \u001b[39m    An iterator of FrameInfo and RepeatedFrames objects representing\u001b[39;00m\n\u001b[0;32m    558\u001b[0m \u001b[39m    a full traceback or stack. Similar consecutive frames are collapsed into RepeatedFrames\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[39m    and optionally an Options object to configure.\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 564\u001b[0m     stack \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(iter_stack(frame_or_tb))\n\u001b[0;32m    566\u001b[0m     \u001b[39m# Reverse the stack from a frame so that it's in the same order\u001b[39;00m\n\u001b[0;32m    567\u001b[0m     \u001b[39m# as the order from a traceback, which is the order of a printed\u001b[39;00m\n\u001b[0;32m    568\u001b[0m     \u001b[39m# traceback when read top to bottom (most recent call last)\u001b[39;00m\n\u001b[0;32m    569\u001b[0m     \u001b[39mif\u001b[39;00m is_frame(frame_or_tb):\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\stack_data\\utils.py:97\u001b[0m, in \u001b[0;36miter_stack\u001b[1;34m(frame_or_tb)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39mwhile\u001b[39;00m frame_or_tb:\n\u001b[0;32m     96\u001b[0m     \u001b[39myield\u001b[39;00m frame_or_tb\n\u001b[1;32m---> 97\u001b[0m     \u001b[39mif\u001b[39;00m is_frame(frame_or_tb):\n\u001b[0;32m     98\u001b[0m         frame_or_tb \u001b[39m=\u001b[39m frame_or_tb\u001b[39m.\u001b[39mf_back\n\u001b[0;32m     99\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\stack_data\\utils.py:90\u001b[0m, in \u001b[0;36mis_frame\u001b[1;34m(frame_or_tb)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_frame\u001b[39m(frame_or_tb: Union[FrameType, TracebackType]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m---> 90\u001b[0m     assert_(\u001b[39misinstance\u001b[39;49m(frame_or_tb, (types\u001b[39m.\u001b[39;49mFrameType, types\u001b[39m.\u001b[39;49mTracebackType)))\n\u001b[0;32m     91\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39misinstance\u001b[39m(frame_or_tb, (types\u001b[39m.\u001b[39mFrameType,))\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\stack_data\\utils.py:171\u001b[0m, in \u001b[0;36massert_\u001b[1;34m(condition, error)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(error, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    170\u001b[0m     error \u001b[39m=\u001b[39m \u001b[39mAssertionError\u001b[39;00m(error)\n\u001b[1;32m--> 171\u001b[0m \u001b[39mraise\u001b[39;00m error\n",
            "\u001b[1;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# inference.py\n",
        "# Copyright 2020 LMNT, Inc. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "#from diffwave.params import AttrDict, params as base_params\n",
        "#from diffwave.model import DiffWave\n",
        "\n",
        "\n",
        "models = {}\n",
        "\n",
        "def predict(spectrogram=None, model_dir=None, params=None, device=torch.device('cuda'), fast_sampling=False):\n",
        "  # Lazy load model.\n",
        "  if not model_dir in models:\n",
        "    if os.path.exists(f'{model_dir}/weights.pt'):\n",
        "      checkpoint = torch.load(f'{model_dir}/weights.pt')\n",
        "    else:\n",
        "      checkpoint = torch.load(model_dir)\n",
        "    model = DiffWave(AttrDict(base_params)).to(device)\n",
        "    model.load_state_dict(checkpoint['model'])\n",
        "    model.eval()\n",
        "    models[model_dir] = model\n",
        "\n",
        "  model = models[model_dir]\n",
        "  model.params.override(params)\n",
        "  with torch.no_grad():\n",
        "    # Change in notation from the DiffWave paper for fast sampling.\n",
        "    # DiffWave paper -> Implementation below\n",
        "    # --------------------------------------\n",
        "    # alpha -> talpha\n",
        "    # beta -> training_noise_schedule\n",
        "    # gamma -> alpha\n",
        "    # eta -> beta\n",
        "    training_noise_schedule = np.array(model.params.noise_schedule)\n",
        "    inference_noise_schedule = np.array(model.params.inference_noise_schedule) if fast_sampling else training_noise_schedule\n",
        "\n",
        "    talpha = 1 - training_noise_schedule\n",
        "    talpha_cum = np.cumprod(talpha)\n",
        "\n",
        "    beta = inference_noise_schedule\n",
        "    alpha = 1 - beta\n",
        "    alpha_cum = np.cumprod(alpha)\n",
        "\n",
        "    T = []\n",
        "    for s in range(len(inference_noise_schedule)):\n",
        "      for t in range(len(training_noise_schedule) - 1):\n",
        "        if talpha_cum[t+1] <= alpha_cum[s] <= talpha_cum[t]:\n",
        "          twiddle = (talpha_cum[t]**0.5 - alpha_cum[s]**0.5) / (talpha_cum[t]**0.5 - talpha_cum[t+1]**0.5)\n",
        "          T.append(t + twiddle)\n",
        "          break\n",
        "    T = np.array(T, dtype=np.float32)\n",
        "\n",
        "\n",
        "    if not model.params.unconditional:\n",
        "      if len(spectrogram.shape) == 2:# Expand rank 2 tensors by adding a batch dimension.\n",
        "        spectrogram = spectrogram.unsqueeze(0)\n",
        "      spectrogram = spectrogram.to(device)\n",
        "      audio = torch.randn(spectrogram.shape[0], model.params.hop_samples * spectrogram.shape[-1], device=device)\n",
        "    else:\n",
        "      audio = torch.randn(1, params.audio_len, device=device)\n",
        "    noise_scale = torch.from_numpy(alpha_cum**0.5).float().unsqueeze(1).to(device)\n",
        "\n",
        "    for n in range(len(alpha) - 1, -1, -1):\n",
        "      c1 = 1 / alpha[n]**0.5\n",
        "      c2 = beta[n] / (1 - alpha_cum[n])**0.5\n",
        "      audio = c1 * (audio - c2 * model(audio, torch.tensor([T[n]], device=audio.device), spectrogram).squeeze(1))\n",
        "      if n > 0:\n",
        "        noise = torch.randn_like(audio)\n",
        "        sigma = ((1.0 - alpha_cum[n-1]) / (1.0 - alpha_cum[n]) * beta[n])**0.5\n",
        "        audio += sigma * noise\n",
        "      audio = torch.clamp(audio, -1.0, 1.0)\n",
        "  return audio, model.params.sample_rate\n",
        "\n",
        "\n",
        "def main(args):\n",
        "  if args.spectrogram_path:\n",
        "    spectrogram = torch.from_numpy(np.load(args.spectrogram_path))\n",
        "  else:\n",
        "    spectrogram = None\n",
        "  audio, sr = predict(spectrogram, model_dir=args.model_dir, fast_sampling=args.fast, params=base_params)\n",
        "  torchaudio.save(args.output, audio.cpu(), sample_rate=sr)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  parser = ArgumentParser(description='runs inference on a spectrogram file generated by diffwave.preprocess')\n",
        "  parser.add_argument('model_dir',\n",
        "      help='directory containing a trained model (or full path to weights.pt file)')\n",
        "  parser.add_argument('--spectrogram_path', '-s',\n",
        "      help='path to a spectrogram file generated by diffwave.preprocess')\n",
        "  parser.add_argument('--output', '-o', default='output.wav',\n",
        "      help='output file name')\n",
        "  parser.add_argument('--fast', '-f', action='store_true',\n",
        "      help='fast sampling procedure')\n",
        "  main(parser.parse_args())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# learner.py\n",
        "#  Copyright 2020 LMNT, Inc. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.nn.parallel import DistributedDataParallel\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "\n",
        "#from diffwave.dataset import from_path, from_gtzan\n",
        "#from diffwave.model import DiffWave\n",
        "#from diffwave.params import AttrDict\n",
        "\n",
        "\n",
        "def _nested_map(struct, map_fn):\n",
        "  if isinstance(struct, tuple):\n",
        "    return tuple(_nested_map(x, map_fn) for x in struct)\n",
        "  if isinstance(struct, list):\n",
        "    return [_nested_map(x, map_fn) for x in struct]\n",
        "  if isinstance(struct, dict):\n",
        "    return { k: _nested_map(v, map_fn) for k, v in struct.items() }\n",
        "  return map_fn(struct)\n",
        "\n",
        "\n",
        "class DiffWaveLearner:\n",
        "  def __init__(self, model_dir, model, dataset, optimizer, params, *args, **kwargs):\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    self.model_dir = model_dir\n",
        "    self.model = model\n",
        "    self.dataset = dataset\n",
        "    self.optimizer = optimizer\n",
        "    self.params = params\n",
        "    self.autocast = torch.cuda.amp.autocast(enabled=kwargs.get('fp16', False))\n",
        "    self.scaler = torch.cuda.amp.GradScaler(enabled=kwargs.get('fp16', False))\n",
        "    self.step = 0\n",
        "    self.is_master = True\n",
        "\n",
        "    beta = np.array(self.params.noise_schedule)\n",
        "    noise_level = np.cumprod(1 - beta)\n",
        "    self.noise_level = torch.tensor(noise_level.astype(np.float32))\n",
        "    self.loss_fn = nn.L1Loss()\n",
        "    self.summary_writer = None\n",
        "\n",
        "  def state_dict(self):\n",
        "    if hasattr(self.model, 'module') and isinstance(self.model.module, nn.Module):\n",
        "      model_state = self.model.module.state_dict()\n",
        "    else:\n",
        "      model_state = self.model.state_dict()\n",
        "    return {\n",
        "        'step': self.step,\n",
        "        'model': { k: v.cpu() if isinstance(v, torch.Tensor) else v for k, v in model_state.items() },\n",
        "        'optimizer': { k: v.cpu() if isinstance(v, torch.Tensor) else v for k, v in self.optimizer.state_dict().items() },\n",
        "        'params': dict(self.params),\n",
        "        'scaler': self.scaler.state_dict(),\n",
        "    }\n",
        "\n",
        "  def load_state_dict(self, state_dict):\n",
        "    if hasattr(self.model, 'module') and isinstance(self.model.module, nn.Module):\n",
        "      self.model.module.load_state_dict(state_dict['model'])\n",
        "    else:\n",
        "      self.model.load_state_dict(state_dict['model'])\n",
        "    self.optimizer.load_state_dict(state_dict['optimizer'])\n",
        "    self.scaler.load_state_dict(state_dict['scaler'])\n",
        "    self.step = state_dict['step']\n",
        "\n",
        "  def save_to_checkpoint(self, filename='weights'):\n",
        "    save_basename = f'{filename}-{self.step}.pt'\n",
        "    save_name = f'{self.model_dir}/{save_basename}'\n",
        "    link_name = f'{self.model_dir}/{filename}.pt'\n",
        "    torch.save(self.state_dict(), save_name)\n",
        "    if os.name == 'nt':\n",
        "      torch.save(self.state_dict(), link_name)\n",
        "    else:\n",
        "      if os.path.islink(link_name):\n",
        "        os.unlink(link_name)\n",
        "      os.symlink(save_basename, link_name)\n",
        "\n",
        "  def restore_from_checkpoint(self, filename='weights'):\n",
        "    try:\n",
        "      checkpoint = torch.load(f'{self.model_dir}/{filename}.pt')\n",
        "      self.load_state_dict(checkpoint)\n",
        "      return True\n",
        "    except FileNotFoundError:\n",
        "      return False\n",
        "\n",
        "  def train(self, max_steps=None):\n",
        "    device = next(self.model.parameters()).device\n",
        "    while True:\n",
        "      for features in tqdm(self.dataset, desc=f'Epoch {self.step // len(self.dataset)}') if self.is_master else self.dataset:\n",
        "        if max_steps is not None and self.step >= max_steps:\n",
        "          return\n",
        "        features = _nested_map(features, lambda x: x.to(device) if isinstance(x, torch.Tensor) else x)\n",
        "        loss = self.train_step(features)\n",
        "        if torch.isnan(loss).any():\n",
        "          raise RuntimeError(f'Detected NaN loss at step {self.step}.')\n",
        "        if self.is_master:\n",
        "          if self.step % 50 == 0:\n",
        "            self._write_summary(self.step, features, loss)\n",
        "          if self.step % len(self.dataset) == 0:\n",
        "            self.save_to_checkpoint()\n",
        "        self.step += 1\n",
        "\n",
        "  def train_step(self, features):\n",
        "    for param in self.model.parameters():\n",
        "      param.grad = None\n",
        "\n",
        "    audio = features['audio']\n",
        "    spectrogram = features['spectrogram']\n",
        "\n",
        "    N, T = audio.shape\n",
        "    device = audio.device\n",
        "    self.noise_level = self.noise_level.to(device)\n",
        "\n",
        "    with self.autocast:\n",
        "      t = torch.randint(0, len(self.params.noise_schedule), [N], device=audio.device)\n",
        "      noise_scale = self.noise_level[t].unsqueeze(1)\n",
        "      noise_scale_sqrt = noise_scale**0.5\n",
        "      noise = torch.randn_like(audio)\n",
        "      noisy_audio = noise_scale_sqrt * audio + (1.0 - noise_scale)**0.5 * noise\n",
        "\n",
        "      predicted = self.model(noisy_audio, t, spectrogram)\n",
        "      loss = self.loss_fn(noise, predicted.squeeze(1))\n",
        "\n",
        "    self.scaler.scale(loss).backward()\n",
        "    self.scaler.unscale_(self.optimizer)\n",
        "    self.grad_norm = nn.utils.clip_grad_norm_(self.model.parameters(), self.params.max_grad_norm or 1e9)\n",
        "    self.scaler.step(self.optimizer)\n",
        "    self.scaler.update()\n",
        "    return loss\n",
        "\n",
        "  def _write_summary(self, step, features, loss):\n",
        "    writer = self.summary_writer or SummaryWriter(self.model_dir, purge_step=step)\n",
        "    writer.add_audio('feature/audio', features['audio'][0], step, sample_rate=self.params.sample_rate)\n",
        "    if not self.params.unconditional:\n",
        "      writer.add_image('feature/spectrogram', torch.flip(features['spectrogram'][:1], [1]), step)\n",
        "    writer.add_scalar('train/loss', loss, step)\n",
        "    writer.add_scalar('train/grad_norm', self.grad_norm, step)\n",
        "    writer.flush()\n",
        "    self.summary_writer = writer\n",
        "\n",
        "\n",
        "def _train_impl(replica_id, model, dataset, args, params):\n",
        "  torch.backends.cudnn.benchmark = True\n",
        "  opt = torch.optim.Adam(model.parameters(), lr=params.learning_rate)\n",
        "\n",
        "  learner = DiffWaveLearner(args.model_dir, model, dataset, opt, params, fp16=args.fp16)\n",
        "  learner.is_master = (replica_id == 0)\n",
        "  learner.restore_from_checkpoint()\n",
        "  learner.train(max_steps=args.max_steps)\n",
        "\n",
        "\n",
        "def train(args, params):\n",
        "  if args.data_dirs[0] == 'gtzan':\n",
        "    dataset = from_gtzan(params)\n",
        "  else:\n",
        "    dataset = from_path(args.data_dirs, params)\n",
        "  model = DiffWave(params).cuda()\n",
        "  _train_impl(0, model, dataset, args, params)\n",
        "\n",
        "\n",
        "def train_distributed(replica_id, replica_count, port, args, params):\n",
        "  os.environ['MASTER_ADDR'] = 'localhost'\n",
        "  os.environ['MASTER_PORT'] = str(port)\n",
        "  torch.distributed.init_process_group('nccl', rank=replica_id, world_size=replica_count)\n",
        "  if args.data_dirs[0] == 'gtzan':\n",
        "    dataset = from_gtzan(params, is_distributed=True)\n",
        "  else:\n",
        "    dataset = from_path(args.data_dirs, params, is_distributed=True)\n",
        "  device = torch.device('cuda', replica_id)\n",
        "  torch.cuda.set_device(device)\n",
        "  model = DiffWave(params).to(device)\n",
        "  model = DistributedDataParallel(model, device_ids=[replica_id])\n",
        "  _train_impl(replica_id, model, dataset, args, params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model.py\n",
        "#  Copyright 2020 LMNT, Inc. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from math import sqrt\n",
        "\n",
        "\n",
        "Linear = nn.Linear\n",
        "ConvTranspose2d = nn.ConvTranspose2d\n",
        "\n",
        "\n",
        "def Conv1d(*args, **kwargs):\n",
        "  layer = nn.Conv1d(*args, **kwargs)\n",
        "  nn.init.kaiming_normal_(layer.weight)\n",
        "  return layer\n",
        "\n",
        "\n",
        "@torch.jit.script\n",
        "def silu(x):\n",
        "  return x * torch.sigmoid(x)\n",
        "\n",
        "\n",
        "class DiffusionEmbedding(nn.Module):\n",
        "  def __init__(self, max_steps):\n",
        "    super().__init__()\n",
        "    self.register_buffer('embedding', self._build_embedding(max_steps), persistent=False)\n",
        "    self.projection1 = Linear(128, 512)\n",
        "    self.projection2 = Linear(512, 512)\n",
        "\n",
        "  def forward(self, diffusion_step):\n",
        "    if diffusion_step.dtype in [torch.int32, torch.int64]:\n",
        "      x = self.embedding[diffusion_step]\n",
        "    else:\n",
        "      x = self._lerp_embedding(diffusion_step)\n",
        "    x = self.projection1(x)\n",
        "    x = silu(x)\n",
        "    x = self.projection2(x)\n",
        "    x = silu(x)\n",
        "    return x\n",
        "\n",
        "  def _lerp_embedding(self, t):\n",
        "    low_idx = torch.floor(t).long()\n",
        "    high_idx = torch.ceil(t).long()\n",
        "    low = self.embedding[low_idx]\n",
        "    high = self.embedding[high_idx]\n",
        "    return low + (high - low) * (t - low_idx)\n",
        "\n",
        "  def _build_embedding(self, max_steps):\n",
        "    steps = torch.arange(max_steps).unsqueeze(1)  # [T,1]\n",
        "    dims = torch.arange(64).unsqueeze(0)          # [1,64]\n",
        "    table = steps * 10.0**(dims * 4.0 / 63.0)     # [T,64]\n",
        "    table = torch.cat([torch.sin(table), torch.cos(table)], dim=1)\n",
        "    return table\n",
        "\n",
        "\n",
        "class SpectrogramUpsampler(nn.Module):\n",
        "  def __init__(self, n_mels):\n",
        "    super().__init__()\n",
        "    self.conv1 = ConvTranspose2d(1, 1, [3, 32], stride=[1, 16], padding=[1, 8])\n",
        "    self.conv2 = ConvTranspose2d(1, 1,  [3, 32], stride=[1, 16], padding=[1, 8])\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.unsqueeze(x, 1)\n",
        "    x = self.conv1(x)\n",
        "    x = F.leaky_relu(x, 0.4)\n",
        "    x = self.conv2(x)\n",
        "    x = F.leaky_relu(x, 0.4)\n",
        "    x = torch.squeeze(x, 1)\n",
        "    return x\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, n_mels, residual_channels, dilation, uncond=False):\n",
        "    '''\n",
        "    :param n_mels: inplanes of conv1x1 for spectrogram conditional\n",
        "    :param residual_channels: audio conv\n",
        "    :param dilation: audio conv dilation\n",
        "    :param uncond: disable spectrogram conditional\n",
        "    '''\n",
        "    super().__init__()\n",
        "    self.dilated_conv = Conv1d(residual_channels, 2 * residual_channels, 3, padding=dilation, dilation=dilation)\n",
        "    self.diffusion_projection = Linear(512, residual_channels)\n",
        "    if not uncond: # conditional model\n",
        "      self.conditioner_projection = Conv1d(n_mels, 2 * residual_channels, 1)\n",
        "    else: # unconditional model\n",
        "      self.conditioner_projection = None\n",
        "\n",
        "    self.output_projection = Conv1d(residual_channels, 2 * residual_channels, 1)\n",
        "\n",
        "  def forward(self, x, diffusion_step, conditioner=None):\n",
        "    assert (conditioner is None and self.conditioner_projection is None) or \\\n",
        "           (conditioner is not None and self.conditioner_projection is not None)\n",
        "\n",
        "    diffusion_step = self.diffusion_projection(diffusion_step).unsqueeze(-1)\n",
        "    y = x + diffusion_step\n",
        "    if self.conditioner_projection is None: # using a unconditional model\n",
        "      y = self.dilated_conv(y)\n",
        "    else:\n",
        "      conditioner = self.conditioner_projection(conditioner)\n",
        "      y = self.dilated_conv(y) + conditioner\n",
        "\n",
        "    gate, filter = torch.chunk(y, 2, dim=1)\n",
        "    y = torch.sigmoid(gate) * torch.tanh(filter)\n",
        "\n",
        "    y = self.output_projection(y)\n",
        "    residual, skip = torch.chunk(y, 2, dim=1)\n",
        "    return (x + residual) / sqrt(2.0), skip\n",
        "\n",
        "\n",
        "class DiffWave(nn.Module):\n",
        "  def __init__(self, params):\n",
        "    super().__init__()\n",
        "    self.params = params\n",
        "    self.input_projection = Conv1d(1, params.residual_channels, 1)\n",
        "    self.diffusion_embedding = DiffusionEmbedding(len(params.noise_schedule))\n",
        "    if self.params.unconditional: # use unconditional model\n",
        "      self.spectrogram_upsampler = None\n",
        "    else:\n",
        "      self.spectrogram_upsampler = SpectrogramUpsampler(params.n_mels)\n",
        "\n",
        "    self.residual_layers = nn.ModuleList([\n",
        "        ResidualBlock(params.n_mels, params.residual_channels, 2**(i % params.dilation_cycle_length), uncond=params.unconditional)\n",
        "        for i in range(params.residual_layers)\n",
        "    ])\n",
        "    self.skip_projection = Conv1d(params.residual_channels, params.residual_channels, 1)\n",
        "    self.output_projection = Conv1d(params.residual_channels, 1, 1)\n",
        "    nn.init.zeros_(self.output_projection.weight)\n",
        "\n",
        "  def forward(self, audio, diffusion_step, spectrogram=None):\n",
        "    assert (spectrogram is None and self.spectrogram_upsampler is None) or \\\n",
        "           (spectrogram is not None and self.spectrogram_upsampler is not None)\n",
        "    x = audio.unsqueeze(1)\n",
        "    x = self.input_projection(x)\n",
        "    x = F.relu(x)\n",
        "\n",
        "    diffusion_step = self.diffusion_embedding(diffusion_step)\n",
        "    if self.spectrogram_upsampler: # use conditional model\n",
        "      spectrogram = self.spectrogram_upsampler(spectrogram)\n",
        "\n",
        "    skip = None\n",
        "    for layer in self.residual_layers:\n",
        "      x, skip_connection = layer(x, diffusion_step, spectrogram)\n",
        "      skip = skip_connection if skip is None else skip_connection + skip\n",
        "\n",
        "    x = skip / sqrt(len(self.residual_layers))\n",
        "    x = self.skip_projection(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.output_projection(x)\n",
        "    return "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# params.py\n",
        "#  Copyright 2020 LMNT, Inc. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class AttrDict(dict):\n",
        "  def __init__(self, *args, **kwargs):\n",
        "      super(AttrDict, self).__init__(*args, **kwargs)\n",
        "      self.__dict__ = self\n",
        "\n",
        "  def override(self, attrs):\n",
        "    if isinstance(attrs, dict):\n",
        "      self.__dict__.update(**attrs)\n",
        "    elif isinstance(attrs, (list, tuple, set)):\n",
        "      for attr in attrs:\n",
        "        self.override(attr)\n",
        "    elif attrs is not None:\n",
        "      raise NotImplementedError\n",
        "    return self\n",
        "\n",
        "\n",
        "params = AttrDict(\n",
        "    # Training params\n",
        "    batch_size=16,\n",
        "    learning_rate=2e-4,\n",
        "    max_grad_norm=None,\n",
        "\n",
        "    # Data params\n",
        "    sample_rate=22050,\n",
        "    n_mels=80,\n",
        "    n_fft=1024,\n",
        "    hop_samples=256,\n",
        "    crop_mel_frames=62,  # Probably an error in paper.\n",
        "\n",
        "    # Model params\n",
        "    residual_layers=30,\n",
        "    residual_channels=64,\n",
        "    dilation_cycle_length=10,\n",
        "    unconditional = False,\n",
        "    noise_schedule=np.linspace(1e-4, 0.05, 50).tolist(),\n",
        "    inference_noise_schedule=[0.0001, 0.001, 0.01, 0.05, 0.2, 0.5],\n",
        "\n",
        "    # unconditional sample len\n",
        "    audio_len = 22050*5, # unconditional_synthesis_samples\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] dir\n",
            "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9011 --control=9009 --hb=9008 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"4e9f909a-2df9-4c2e-b467-26d216c0eb23\" --shell=9010 --transport=\"tcp\" --iopub=9012\n"
          ]
        },
        {
          "ename": "SystemExit",
          "evalue": "2",
          "output_type": "error",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
          ]
        }
      ],
      "source": [
        "# preprocess.py\n",
        "#  Copyright 2020 LMNT, Inc. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchaudio as T\n",
        "import torchaudio.transforms as TT\n",
        "\n",
        "from argparse import ArgumentParser\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "#from diffwave.params import params\n",
        "\n",
        "\n",
        "def transform(filename):\n",
        "  audio, sr = T.load(filename)\n",
        "  audio = torch.clamp(audio[0], -1.0, 1.0)\n",
        "\n",
        "  if params.sample_rate != sr:\n",
        "    raise ValueError(f'Invalid sample rate {sr}.')\n",
        "  mel_args = {\n",
        "      'sample_rate': sr,\n",
        "      'win_length': params.hop_samples * 4,\n",
        "      'hop_length': params.hop_samples,\n",
        "      'n_fft': params.n_fft,\n",
        "      'f_min': 20.0,\n",
        "      'f_max': sr / 2.0,\n",
        "      'n_mels': params.n_mels,\n",
        "      'power': 1.0,\n",
        "      'normalized': True,\n",
        "  }\n",
        "  mel_spec_transform = TT.MelSpectrogram(**mel_args)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    spectrogram = mel_spec_transform(audio)\n",
        "    spectrogram = 20 * torch.log10(torch.clamp(spectrogram, min=1e-5)) - 20\n",
        "    spectrogram = torch.clamp((spectrogram + 100) / 100, 0.0, 1.0)\n",
        "    np.save(f'{filename}.spec.npy', spectrogram.cpu().numpy())\n",
        "\n",
        "\n",
        "def main(args):\n",
        "  filenames = glob(f'{args.dir}/**/*.wav', recursive=True)\n",
        "  with ProcessPoolExecutor() as executor:\n",
        "    list(tqdm(executor.map(transform, filenames), desc='Preprocessing', total=len(filenames)))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  parser = ArgumentParser(description='prepares a dataset to train DiffWave')\n",
        "  parser.add_argument('dir',\n",
        "      help='directory containing .wav files for training')\n",
        "  main(parser.parse_args())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "License\n",
        "  Apache License\n",
        "                           Version 2.0, January 2004\n",
        "                        http://www.apache.org/licenses/\n",
        "\n",
        "   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n",
        "\n",
        "   1. Definitions.\n",
        "\n",
        "      \"License\" shall mean the terms and conditions for use, reproduction,\n",
        "      and distribution as defined by Sections 1 through 9 of this document.\n",
        "\n",
        "      \"Licensor\" shall mean the copyright owner or entity authorized by\n",
        "      the copyright owner that is granting the License.\n",
        "\n",
        "      \"Legal Entity\" shall mean the union of the acting entity and all\n",
        "      other entities that control, are controlled by, or are under common\n",
        "      control with that entity. For the purposes of this definition,\n",
        "      \"control\" means (i) the power, direct or indirect, to cause the\n",
        "      direction or management of such entity, whether by contract or\n",
        "      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n",
        "      outstanding shares, or (iii) beneficial ownership of such entity.\n",
        "\n",
        "      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n",
        "      exercising permissions granted by this License.\n",
        "\n",
        "      \"Source\" form shall mean the preferred form for making modifications,\n",
        "      including but not limited to software source code, documentation\n",
        "      source, and configuration files.\n",
        "\n",
        "      \"Object\" form shall mean any form resulting from mechanical\n",
        "      transformation or translation of a Source form, including but\n",
        "      not limited to compiled object code, generated documentation,\n",
        "      and conversions to other media types.\n",
        "\n",
        "      \"Work\" shall mean the work of authorship, whether in Source or\n",
        "      Object form, made available under the License, as indicated by a\n",
        "      copyright notice that is included in or attached to the work\n",
        "      (an example is provided in the Appendix below).\n",
        "\n",
        "      \"Derivative Works\" shall mean any work, whether in Source or Object\n",
        "      form, that is based on (or derived from) the Work and for which the\n",
        "      editorial revisions, annotations, elaborations, or other modifications\n",
        "      represent, as a whole, an original work of authorship. For the purposes\n",
        "      of this License, Derivative Works shall not include works that remain\n",
        "      separable from, or merely link (or bind by name) to the interfaces of,\n",
        "      the Work and Derivative Works thereof.\n",
        "\n",
        "      \"Contribution\" shall mean any work of authorship, including\n",
        "      the original version of the Work and any modifications or additions\n",
        "      to that Work or Derivative Works thereof, that is intentionally\n",
        "      submitted to Licensor for inclusion in the Work by the copyright owner\n",
        "      or by an individual or Legal Entity authorized to submit on behalf of\n",
        "      the copyright owner. For the purposes of this definition, \"submitted\"\n",
        "      means any form of electronic, verbal, or written communication sent\n",
        "      to the Licensor or its representatives, including but not limited to\n",
        "      communication on electronic mailing lists, source code control systems,\n",
        "      and issue tracking systems that are managed by, or on behalf of, the\n",
        "      Licensor for the purpose of discussing and improving the Work, but\n",
        "      excluding communication that is conspicuously marked or otherwise\n",
        "      designated in writing by the copyright owner as \"Not a Contribution.\"\n",
        "\n",
        "      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n",
        "      on behalf of whom a Contribution has been received by Licensor and\n",
        "      subsequently incorporated within the Work.\n",
        "\n",
        "   2. Grant of Copyright License. Subject to the terms and conditions of\n",
        "      this License, each Contributor hereby grants to You a perpetual,\n",
        "      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n",
        "      copyright license to reproduce, prepare Derivative Works of,\n",
        "      publicly display, publicly perform, sublicense, and distribute the\n",
        "      Work and such Derivative Works in Source or Object form.\n",
        "\n",
        "   3. Grant of Patent License. Subject to the terms and conditions of\n",
        "      this License, each Contributor hereby grants to You a perpetual,\n",
        "      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n",
        "      (except as stated in this section) patent license to make, have made,\n",
        "      use, offer to sell, sell, import, and otherwise transfer the Work,\n",
        "      where such license applies only to those patent claims licensable\n",
        "      by such Contributor that are necessarily infringed by their\n",
        "      Contribution(s) alone or by combination of their Contribution(s)\n",
        "      with the Work to which such Contribution(s) was submitted. If You\n",
        "      institute patent litigation against any entity (including a\n",
        "      cross-claim or counterclaim in a lawsuit) alleging that the Work\n",
        "      or a Contribution incorporated within the Work constitutes direct\n",
        "      or contributory patent infringement, then any patent licenses\n",
        "      granted to You under this License for that Work shall terminate\n",
        "      as of the date such litigation is filed.\n",
        "\n",
        "   4. Redistribution. You may reproduce and distribute copies of the\n",
        "      Work or Derivative Works thereof in any medium, with or without\n",
        "      modifications, and in Source or Object form, provided that You\n",
        "      meet the following conditions:\n",
        "\n",
        "      (a) You must give any other recipients of the Work or\n",
        "          Derivative Works a copy of this License; and\n",
        "\n",
        "      (b) You must cause any modified files to carry prominent notices\n",
        "          stating that You changed the files; and\n",
        "\n",
        "      (c) You must retain, in the Source form of any Derivative Works\n",
        "          that You distribute, all copyright, patent, trademark, and\n",
        "          attribution notices from the Source form of the Work,\n",
        "          excluding those notices that do not pertain to any part of\n",
        "          the Derivative Works; and\n",
        "\n",
        "      (d) If the Work includes a \"NOTICE\" text file as part of its\n",
        "          distribution, then any Derivative Works that You distribute must\n",
        "          include a readable copy of the attribution notices contained\n",
        "          within such NOTICE file, excluding those notices that do not\n",
        "          pertain to any part of the Derivative Works, in at least one\n",
        "          of the following places: within a NOTICE text file distributed\n",
        "          as part of the Derivative Works; within the Source form or\n",
        "          documentation, if provided along with the Derivative Works; or,\n",
        "          within a display generated by the Derivative Works, if and\n",
        "          wherever such third-party notices normally appear. The contents\n",
        "          of the NOTICE file are for informational purposes only and\n",
        "          do not modify the License. You may add Your own attribution\n",
        "          notices within Derivative Works that You distribute, alongside\n",
        "          or as an addendum to the NOTICE text from the Work, provided\n",
        "          that such additional attribution notices cannot be construed\n",
        "          as modifying the License.\n",
        "\n",
        "      You may add Your own copyright statement to Your modifications and\n",
        "      may provide additional or different license terms and conditions\n",
        "      for use, reproduction, or distribution of Your modifications, or\n",
        "      for any such Derivative Works as a whole, provided Your use,\n",
        "      reproduction, and distribution of the Work otherwise complies with\n",
        "      the conditions stated in this License.\n",
        "\n",
        "   5. Submission of Contributions. Unless You explicitly state otherwise,\n",
        "      any Contribution intentionally submitted for inclusion in the Work\n",
        "      by You to the Licensor shall be under the terms and conditions of\n",
        "      this License, without any additional terms or conditions.\n",
        "      Notwithstanding the above, nothing herein shall supersede or modify\n",
        "      the terms of any separate license agreement you may have executed\n",
        "      with Licensor regarding such Contributions.\n",
        "\n",
        "   6. Trademarks. This License does not grant permission to use the trade\n",
        "      names, trademarks, service marks, or product names of the Licensor,\n",
        "      except as required for reasonable and customary use in describing the\n",
        "      origin of the Work and reproducing the content of the NOTICE file.\n",
        "\n",
        "   7. Disclaimer of Warranty. Unless required by applicable law or\n",
        "      agreed to in writing, Licensor provides the Work (and each\n",
        "      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n",
        "      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
        "      implied, including, without limitation, any warranties or conditions\n",
        "      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n",
        "      PARTICULAR PURPOSE. You are solely responsible for determining the\n",
        "      appropriateness of using or redistributing the Work and assume any\n",
        "      risks associated with Your exercise of permissions under this License.\n",
        "\n",
        "   8. Limitation of Liability. In no event and under no legal theory,\n",
        "      whether in tort (including negligence), contract, or otherwise,\n",
        "      unless required by applicable law (such as deliberate and grossly\n",
        "      negligent acts) or agreed to in writing, shall any Contributor be\n",
        "      liable to You for damages, including any direct, indirect, special,\n",
        "      incidental, or consequential damages of any character arising as a\n",
        "      result of this License or out of the use or inability to use the\n",
        "      Work (including but not limited to damages for loss of goodwill,\n",
        "      work stoppage, computer failure or malfunction, or any and all\n",
        "      other commercial damages or losses), even if such Contributor\n",
        "      has been advised of the possibility of such damages.\n",
        "\n",
        "   9. Accepting Warranty or Additional Liability. While redistributing\n",
        "      the Work or Derivative Works thereof, You may choose to offer,\n",
        "      and charge a fee for, acceptance of support, warranty, indemnity,\n",
        "      or other liability obligations and/or rights consistent with this\n",
        "      License. However, in accepting such obligations, You may act only\n",
        "      on Your own behalf and on Your sole responsibility, not on behalf\n",
        "      of any other Contributor, and only if You agree to indemnify,\n",
        "      defend, and hold each Contributor harmless for any liability\n",
        "      incurred by, or claims asserted against, such Contributor by reason\n",
        "      of your accepting any such warranty or additional liability.\n",
        "\n",
        "   END OF TERMS AND CONDITIONS\n",
        "\n",
        "   APPENDIX: How to apply the Apache License to your work.\n",
        "\n",
        "      To apply the Apache License to your work, attach the following\n",
        "      boilerplate notice, with the fields enclosed by brackets \"[]\"\n",
        "      replaced with your own identifying information. (Don't include\n",
        "      the brackets!)  The text should be enclosed in the appropriate\n",
        "      comment syntax for the file format. We also recommend that a\n",
        "      file or class name and description of purpose be included on the\n",
        "      same \"printed page\" as the copyright notice for easier\n",
        "      identification within third-party archives.\n",
        "\n",
        "   Copyright [yyyy] [name of copyright owner]\n",
        "\n",
        "   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "   you may not use this file except in compliance with the License.\n",
        "   You may obtain a copy of the License at\n",
        "\n",
        "       http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "   Unless required by applicable law or agreed to in writing, software\n",
        "   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "   See the License for the specific language governing permissions and\n",
        "   limitations under the License.\n",
        "Footer\n",
        " 2022 GitHub, Inc.\n",
        "Footer navigation\n",
        "Terms\n",
        "Privacy\n",
        "Security\n",
        "Status\n",
        "Docs\n",
        "Contact GitHub\n",
        "Pricing\n",
        "API\n",
        "Training\n",
        "Blog\n",
        "About\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyO6e/zwLACkpi+5Tw4v6kuz",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "4032882ddb4612dbc8ae29393ee69028fde08f7d5be80501044e83b7ed30f359"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
